<!DOCTYPE html>
<html>

    <head>
        <meta charset='utf-8'>
        <meta http-equiv='X-UA-Compatible' content='IE=edge'>
        <title>Portfolio Selma El Babarti</title>
        <meta name='viewport' content='width=device-width, initial-scale=1'>
        <link rel='stylesheet' type='text/css' media='screen' href='style.css'>
        <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick.css"/>
        <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick-theme.css"/>

        <script type="text/javascript" src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
        <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick.min.js"></script>

    </head>

<body>
    <header class="header">
        <div class="fixation-header">
            <nav class="navbar">
                <div class = "profile">
                    <img src="img/me.jpg" width="100">
                    <h1>
                        <a href="index.html" style="color: inherit">Selma EL BABARTI</a>
                    </h1>
                </div>
                <ul id="listeMobile" class="liste">
                    <li><a href="parcours.html" style="color: inherit" id="lienPageParcours">Mon parcours</a></li>
                    <li><a href="compétences.html" style="color: inherit" id="lienPageComp">Mes compétences</a></li>
                    <li><a href="projets.html" style="color: inherit"  id="lienPageProjets">Mes projets</a></li>
                    <li><a href="interet.html" style="color: inherit" id="lienPageCentre">Mes centres d'intérêt</a></li>
                    <li>
                        <a href="https://www.linkedin.com/in/selma-el-babarti/"
                        target="_BLANK" style="color: inherit">
                        <svg width="20px" height="20" class="icon linkedin" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z"/></svg>
                        </a>
                    </li>
                </ul>
                <button id="burgerid" class="burger">
                    <a href="#" style="color: inherit">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Pro 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg>
                    </a>
                </button>

                <button id="burgerid2" class="burger" style="display:none">
                    <a href="#" style="color: inherit">
                        <svg xmlns="http://www.w3.org/2000/svg" x="0px" y="0px"
                        width="24" height="24"
                        viewBox="0 0 24 24">
                        <path d="M 4.7070312 3.2929688 L 3.2929688 4.7070312 L 10.585938 12 L 3.2929688 19.292969 L 4.7070312 20.707031 L 12 13.414062 L 19.292969 20.707031 L 20.707031 19.292969 L 13.414062 12 L 20.707031 4.7070312 L 19.292969 3.2929688 L 12 10.585938 L 4.7070312 3.2929688 z"></path>
                        </svg>                    
                    </a>
                </button>
               
            </nav>
        </div>
    </header>

    <section class="page-content">
        <section class="ps7" id="projet">
            <h1>Tu le connais ?</h1>
            <div class="texte">
                <p>Dans le cadre de ma 2ème année de master Cultures Numériques, j'ai eu l'occasion de réaliser un projet dont l'objectif était de réaliser une expérimentation dans un XP-Lab afin de récolter des données en vue d'une analyse pour répondre à une problématique de notre choix. </p>
                <p>Pour cela, le projet s'est déroulé en 2 phases :
                    <br> - Une phase de mise en place d'un protocole d'expérimentation confromément à notre problématique intiale
                    <br> - Une phase d'analyse des données
                </p>
                <h2>Le protocole et la mise en place de l'envrionnement </h2>
                <p> <strong>1. Question de recherche :</strong>
                    <br>Existe-t-il un effet du genre sur l’expérience des émotions ?
                    <br><br><strong>2. Objectif :</strong>
                    <br> Nous allons évaluer s’il existe une différence significative entre l'auto déclaration subjective des sujets et la mesure objective des données, en comparant les hommes et les femmes. 
                    <br><br><strong>3. Hypothèse :</strong>
                    <br>On ne détecte pas ou peu de différences dans l’analyse des données entre les genres, mais une différence significative lors de la comparaison avec leur auto-déclaration (Liapis et al., 2015).
                    <br><br><strong>4. Sous hypothèses :</strong>
                    <br>- Les catégories de photos (personnes familières, connues ou inconnues) influent sur les mesures objectives (GSR, oculométrie et expressions faciales) pour les deux genres.
                    <br>- Les données subjectives présentent une différence significative entre les genres : les femmes ont une meilleure précision de reconnaissance de leurs expériences d’émotions (Liapis et al., 2015).
                    <br>- Les données objectives ne présentent pas de différence significative entre les deux genres.
                    <br><br><strong>5. Expérimentation :</strong>
                    <br>Les sujets vont être confrontés à des photos (visages de personnes, de catégories différentes : familières, connues ou inconnues) et devront évaluer leurs émotions via l’arousal et la valence. Des mesures quantitatives seront récoltées durant le visionnage (GSR, oculométrie et expressions faciales). 
                    <br><br><strong>6. Stimuli :</strong>
                    <br>30 images de différentes catégories : 
                    <br>- 10 images montrant des personnes inconnues
                    <br>- 10 images montrant des personnalités connues (célébrités) : 
                    <br>- 10 images montrant des personnes familières (personnes de la halle 6) :
                    <br><br><strong>Quelques exemples de stimuli</strong>
                </p>
                <div class="carrousel">
                    <div><img height="200px" src="img/ca1/ca1_img1.png"></div>
                    <div><img height="200px" src="img/ca1/ca1_img2.png"></div>
                    <div><img height="200px" src="img/ca1/ca1_img3.png"></div>
                    <div><img height="200px" src="img/ca1/ca1_img4.png"></div>
                    <div><img height="200px" src="img/ca1/ca1_img5.png"></div>
                </div>
                <script>
                    $(document).ready(function(){
                      $('.carrousel').slick({
                        dots: true, // Active les points indicateurs de pagination
                        autoplay: true, // Active la lecture automatique
                        autoplaySpeed: 2000, // Définit la vitesse de lecture automatique (en millisecondes)
                      });
                    });
                </script>
                <p>
                    <br><br><strong>7. Protocole :</strong>
                    <br>Le participant reçoit des explications sur l’expérimentation qui va suivre : durée, données récoltées, objectif, etc.
                    <br>Le participant remplit une fiche de consentement.
                    <br>Le participant est installé à sa place.
                    <br>Les appareils sont calibrés (oculométrie, caméra et capteurs GSR), et l’expérimentateur remplit les données démographiques sur TOBI.
                    <br>Le participant confirme qu’il est prêt.
                    <br>Une image de “Test” est affichée pendant 10 secondes.
                    <br>Le participant répond ensuite à la question de “Test” sur la tablette qui se trouve à côté en disposant de 30 secondes (durée modulable selon les pré-tests). 
                    <br>Si le participant n’a plus de questions et confirme sa compréhension, l’expérimentation débute.
                    <br>Le participant regarde un total de 30 images pendant 10 secondes chacune, avec des intervalles de 30 secondes entre chacune d’elle pour répondre au questionnaire.
                    <br>En fonction des pré-tests que nous allons effectuer, les temps d’affichage des images et des questions pourront évoluer. 
                    <br><br><strong>8. Questions posées dans le questionnaire : </strong>
                    <br>Vous êtes : Une femme - Un homme (case à cocher) (Posée une seule fois au début)
                    <br>Connaissez-vous cette personne ? Oui - Non (case à cocher) 
                    <br>Si oui, la connaissez-vous personnellement (faire apparaître que si la réponse d’avant était oui) : Oui - Non 
                    <br>Echelle de Likert : Placer sur cette échelle le degré de positivité ou négativité de ce que vous avez ressenti en voyant cette image (1= négatif, 9=positif)
                    <br>Échelle de Likert : Placer sur cette échelle le degré d’intensité de ce que vous avez ressenti en voyant cette image (1= calme, 9= excitation)
                    <br>Quelle type d’émotion diriez-vous que vous avez ressenti (case à cocher) : 
                    <br>- En colère
                    <br>- Dégouté
                    <br>- Apeuré
                    <br>- Heureux
                    <br>- Triste
                    <br>- Surpris
                    <br>- Neutre
                    <br><br><strong>9. Analyses prévues : </strong>
                    <br><br><strong>Données GSR : </strong>
                    <br>Analyse de l’intensité des émotions en fonction des catégories d’images. En se basant sur le notebook fourni, nous allons essayer de détecter des “pics” d’intensité ou leur fréquence.
                    <br><br><strong>Données d’oculométrie : </strong>
                    <br>Analyse du mouvement du regard en fonction des catégories d’images. Cartes de saillance etc sur les zones fixées (par exemple yeux, nez, bouche…)
                    <br><br><strong>Données de la webcam : </strong>
                    <br>Analyse des émotions faciales avec l’algorithme de détection Face Coding.  
                    <br><br><strong>Données du questionnaire : </strong>
                    <br>Comparaison de la précision de l’auto-déclaration des émotions par rapport aux données objectives listées ci-dessus.
                    <br>Comparaison globale sur les genres 
                </p>
                <h2>L'analyse des données</h2>
                <p>Les données ont été traitées et analysées avec l'outil Jupyter Notebook</p>
                <div class="rapport">
                    <a href="img/ca1/ca1_slides.pdf" class="btn" target="_BLANK" role="button">Voir le rapport d'analyse des données</a>
                </div>
            </div>
        </section>

   </section>

   <footer class="footer">
        <div class="coordonnees">
            <h3 id="contact">Mes coordonnées</h3>
            <p><a href="mailto:selma.elbabarti@gmail.com">selma.elbabarti@gmail.com</a></p>
            <p><a href="mailto:selma.el-babarti@etu.univ-nantes.fr">selma.el-babarti@etu.univ-nantes.fr</a></p>
            <p>07.50.23.05.18</p>
        </div>
        <div class="image">
            <img src="img/logo.png" ></img>
        </div>
    </footer>
    <script src='main.js'></script>
</body>
</html>